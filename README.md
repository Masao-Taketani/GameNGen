# Diffusion Models Are Real-Time Game Engines

This is an unofficial repo of [GameNGen](https://arxiv.org/abs/2408.14837). I have referred to [arnaudstiegler/gameNgen-repro](https://github.com/arnaudstiegler/gameNgen-repro/tree/main) in order to create this repo.

## Modifications
Here are the list of modifications from [arnaudstiegler/gameNgen-repro](https://github.com/arnaudstiegler/gameNgen-repro/tree/main).
- Fixed the environment setup with Anaconda and write down the precise commands in order to properly reproduce the code.
- Fixed the training steps to properly train the PPO agents within VizDoom environment

## To Do
- Enable to generate dataset with multiprocessing
- Enable distributed training
- Implement playable generative environment

## Artifacts

All artifacts are available on Hugging Face Hub:

Checkpoints:
- [gameNgen-baseline-20ksteps](https://huggingface.co/arnaudstiegler/gameNgen-baseline-20ksteps)
- [sd-model-gameNgen-60ksteps](https://huggingface.co/arnaudstiegler/sd-model-gameNgen-60ksteps)

Datasets:
- [vizdoom-5-episodes-skipframe-4-lvl5](https://huggingface.co/arnaudstiegler/vizdoom-5-episodes-skipframe-4-lvl5)
- [vizdoom-500-episodes-skipframe-4-lvl5](https://huggingface.co/arnaudstiegler/vizdoom-500-episodes-skipframe-4-lvl5)

Vizdoom Agent:
- `ViZDoomPPO/logs/models/deathmatch_simple/best_model.zip` (local)

## Scripts

### Generate the training data

First, follow the commands below in order to create an environment to train Vizdoom agent.
```
conda create -n vizdoom python=3.11 -y
conda activate vizdoom
apt update && apt install libgl1 swig g++ -y
pip install setuptools==65.5.0 pip==21 wheel==0.38.0
cd ViZDoomPPO/
pip install -r vizdoom_requirements.txt
```

Then, run the following command to train an agent on vizdoom:
```
python train_ppo_parallel.py
```

Once the agent is trained, generate episodes and upload them as a HF dataset using:
```
python load_model_generate_dataset.py --episodes {number of episodes} --output parquet --upload --hf_repo {name of the repo}
```

Note: you can also generate a gif file to QA the behavior of the agent by running:
```
python load_model_generate_dataset.py --episodes 1 --output gif
```


### Train the diffusion model

Second step is that follow the commands below in order to create an environment to train diffusion model.
```
conda deactivate
conda create -n diffusion python=3.11 -y
conda activate diffusion
pip install -r diffusion_requirements.txt
```

Debug on a single sample:
```
python train_text_to_image.py  \
    --dataset_name arnaudstiegler/vizdoom-episode  \
    --gradient_checkpointing  \
    --train_batch_size 12  \
    --learning_rate 5e-5  \
    --num_train_epochs 1500  \
    --validation_steps 250  \
    --dataloader_num_workers 18 \
    --max_train_samples 2 \
    --use_cfg \
    --report_to wandb
```

Full training
```
python train_text_to_image.py \
    --dataset_name arnaudstiegler/vizdoom-500-episodes-skipframe-4-lvl5 \
    --gradient_checkpointing \
    --learning_rate 5e-5 \
    --train_batch_size 12 \
    --dataloader_num_workers 18 \
    --num_train_epochs 3 \
    --validation_steps 1000 \
    --use_cfg \
    --output_dir sd-model-finetuned \
    --push_to_hub \
    --lr_scheduler cosine \
    --report_to wandb
```

### Train the auto-encoder

```
python finetune_autoencoder.py --hf_model_folder {path to the model folder}
```

### Run inference (generating a single image)

```
python run_inference.py --model_folder arnaudstiegler/sd-model-gameNgen-60ksteps
```

### Run autoregressive inference

This will generate rollouts, where each new frame is generated by the model conditioned on the previous frames and actions.
We initially fill the buffer using the small dataset, and sample actions from the dataset (i.e it matches what the agent did in the episode)

```
python run_autoregressive.py --model_folder arnaudstiegler/sd-model-gameNgen-60ksteps
```

## References

### Paper
- [Diffusion Models Are Real-Time Game Engines](https://arxiv.org/abs/2408.14837)

### GitHub Repos
- [arnaudstiegler/gameNgen-repro](https://github.com/arnaudstiegler/gameNgen-repro/tree/main)